# Foreword {-}

*Author: Przemyslaw Biecek ([Warsaw University of Technology](https://mini.pw.edu.pl) and [University of Warsaw](https://www.mimuw.edu.pl/))*

## Why?

Machine learning has a number of applications. Very often, however, machine learning predictive models are treated as black boxes which can be automatically trained without worrying about the domain in which they are used.
This opaqueness rises many risks that are difficult to foresee during the model building process. Such as the model's declining performance due to the data drift, poor performance on the out-of-domain problems or unfair biased behaviour learned on historical data.

The growing list of examples where black boxes fail spectacularly has led to an increased interest in XAI methods. Such methods allow to x-ray black boxes models for more detailed analysis on the local or global level. 

According to [Gartner Hype Cycle for Emerging Technologies in 2019](https://www.gartner.com/smarterwithgartner/5-trends-appear-on-the-gartner-hype-cycle-for-emerging-technologies-2019/) Explainable AI is on the verge of *Innovation trigger* and *Peak of inflated expectations*. It is a technology with a very high potential, which is talked about a lot in the media and which heats up the imagination as strongly as AI.

In the literature there are many articles arguing the need to use XAI methods as well as many ideas for new methods from the XAI family. However, it is much more difficult to find examples of successful implementations of XAI methods that have improved the business.

Missing elements are case studies of actual use of XAI methods in machine learning problems. Such case studies would allow a better understanding of what is possible today and what is not possible using XAI methods.

## What?

**This ebook collects examples of the use of different methods from the XAI family for different real-world predictive problems.**
In the following chapters, we show example applications of different XAI techniques to problems based on real-world public dataset.

These examples are called *XAI stories* and like every good story, each one has a structure. It starts with a description of the predictive problem, goes on to describe the proposed model or models. The models are x-rays using XAI techniques to finish the chapter with a point.

## How?

For XAI stories to be credible they need not only a strong predictive model, but also business validation of the proposed modeling and explanation approach. 

Each group of students got two mentors from McKinsey's Data Science department. The mentors, together with the students, searched for strengths and weaknesses of XAI applications in specific problems.
